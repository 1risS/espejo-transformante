<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Espejo transformante para Programación de entornos sensoriales 1</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.dom/1.1.0/p5.dom.min.js"></script>
    <script src="https://tonejs.github.io/build/Tone.js"></script>
    <script src="sketch.js" defer></script>
    <script src="flow.js"></script>
</head>

<body>
    <div className="page-container">
        <header>
            <h1>Espejo Transformante</h1>
            <h2>Programación de Entornos Sensoriales I 2024</h2>
            <h3>Profesores Emiliano Causa y Matías Romero Costas</h3>
            <h4>Maestría en Tecnologías y Estéticas de las Artes Electrónicas UNTreF</h4>
        </header>

        <div id="container">
            <h2>Sobre el proyecto</h2>
            <p>
                Se trata de una experiencia en la que unx o más visitantes pueden
                modificar la trayectoria de pelotitas en el espacio de la pantalla
                gracias a la estimación del flujo óptico que permite calcular vectores
                de movimiento de acuerdo a la diferencia de luminancia entre fotogramas.
                Con estos valores se afecta la dirección de las pelotitas que se mueven.
                La interacción se realiza a través de la cámara web de la computadora.
                Finalmente, al rebotar en los bordes de la pantalla, las pelositas
                disparan un sonido manejado con tone.js.
            </p>

            <!-- Container for the p5.js sketch -->
            <div id="canvas-container"></div>

            <div className="explanation-container">
                <h2>¿Cómo funciona?</h2>
                <p> Para crear este ejercicio partí de <a href="https://editor.p5js.org/jeffThompson/sketches/DfsmBZ9O0"
                        target="blank">este ejemplo</a>
                    y comencé a pedirle explicaciones y código a chatGPT. El resultado es el código fuente de esta
                    página, el cual está disponible <a href="https://github.com/1risS/espejo-transformante"
                        target="blank">aquí</a>. También el título de cada parte del código es un enlace al archivo
                    correspondiente en el repositorio.
                </p>
                <p>A continuación voy a explicar parte por parte todo el código.</p>
                <!-- index.html -->
                <h2><a href="https://github.com/1risS/espejo-transformante/blob/main/index.html">index.html</a></h2>
                <p>En este archivo se importan las librerías necesarias para el proyecto, en este caso <a
                        href="https://p5js.org/" target="blank">p5.js</a> y <a href="https://tonejs.github.io/"
                        target="blank">tone.js</a>, y también los scripts en <a
                        href="https://simple.wikipedia.org/wiki/JavaScript" target="blank"> JavaScript</a> que contienen
                    la lógica de este programa.</p>
                <img src="./assets/index-librerias.png" alt="index.html" style="height: 200px;" />

                <p>En este archivo, además, se determinan los elementos visuales en la página. A continuación pego una
                    captura parcial del archivo.</p>
                <img src="./assets/elementos-visuales.png" alt="index.html" style="height: 400px;" />
                <!-- flow.js -->
                <h2><a href="https://github.com/1risS/espejo-transformante/blob/main/flow.js"
                        target="_blank">flow.js</a></h2>
                <h3>¿Qué hace la clase FlowZone?</h3>
                <p>La clase FlowZone guarda información sobre un lugar específico en la imagen:

                    <b>x</b> y <b>y</b>: Representan la posición del lugar en la imagen (un punto).
                    <b>u</b> y <b>v</b>: Representan hacia dónde y con qué fuerza parece moverse ese punto (el
                    "flujo" horizontal y vertical).
                </p>
                <img src="./assets/flow-zone.png" alt="FlowZone" style="height: 200px;" />

                <h3>¿Qué hace la clase FlowCalculator?</h3>
                <p>La clase FlowCalculator calcula el flujo óptico entre dos fotogramas consecutivos de un video
                    con el objetivo de encontrar zonas "de flujo", es decir, de movimiento, implementando
                    <a href="https://es.wikipedia.org/wiki/M%C3%A9todo_Lucas%E2%80%93Kanade" target="_blank">el
                        algoritmo de Lucas-Kanade.</a>
                </p>
                <img src="./assets/flow-calculator.png" alt="FlowCalculator" style="height: 600px;" />
                <p>
                    El programa se mueve en pasos (definidos por step, que es 8 por defecto).
                    Esto significa que no analiza cada píxel uno por uno, sino que salta pequeños bloques de 8 en 8 para
                    ser más eficiente.
                    Para detectar movimiento se fija en dos imágenes (la anterior y la actual) y compara cómo han
                    cambiado los colores de cada área.
                    Para cada área calcula un promedio del color (lo convierte a blanco y negro para simplificar),
                    ve si el color cambió y en qué dirección. Si el cambio supera el valor definido en la variable
                    <b>score</b> (en el ejercicio actual este valor es 50),
                    detecta movimiento y guarda los valores del mismo en la variable <b>this.zones</b>.
                </p>

                <!-- sketch.js -->
                <h2><a href="https://github.com/1risS/espejo-transformante/blob/main/sketch.js"
                        target="_blank">sketch.js</a></h2>
                <p>Este archivo crea un programa interactivo que utiliza una cámara web para generar un efecto visual
                    con "pelotitas" que se mueven y rebotan en los bordes de la pantalla, produciendo sonidos cuando lo
                    hacen. </p>

                <h3>Variables globales</h3>

                <p>Lo primero que se presenta son las variables globales, a saber:
                <ul>
                    <li><b>h</b> y <b>w</b> que representan el alto y
                        el ancho del canvas,</li>
                    <li><b>capture</b> que guarda una referencia a un objeto de captura de video, el cual es utilizado
                        para
                        capturar video de una webcam,</li>
                    <li><b>previousPixels</b> que guarda los valores de color de los píxeles en un frame previo, lo cual
                        es
                        útil para hacer comparación de frames,</li>
                    <li><b>flow</b> guarda una instancia de la clase <b>FlowCalculator</b>, </li>
                    <li><b>step</b> inicializa los saltos de píxeles para el cálculo del flujo óptico con valor 8,</li>
                    <li><b>balls</b> se inicializa como un array vacío que será usado para guardar los objetos
                        <b>ball</b>,
                        las "pelotitas" que se mueven en el canvas, y por último,
                    </li>
                    <li><b>leftSynth</b>, <b>rightSynth</b>, <b>topSynth</b> y <b>bottomSynth</b> guardan referencias a
                        objetos sintetizadores de <b>tone.js</b>
                        para que suenen en los bordes del canvas cada vez que los impacta una "pelotita".</li>
                </ul>
                </p>
                <img src="./assets/variables-globales.png" style="height: 200px;" />

                <h3>Función setup()</h3>

                <p>Este bloque configura todo lo que el programa necesita para empezar:
                <ul>
                    <li><b>Canvas:</b> Se crea un área donde se dibuja todo, llamada canvas. Se coloca dentro de un
                        contenedor HTML llamado canvas-container.</li>
                    <li><b>Cámara:</b> Se activa la cámara para capturar video y se oculta la vista directa de la cámara
                        para manipularla en el canvas.</li>
                    <li><b>FlowCalculator:</b> Es una herramienta que analiza el video y detecta movimiento en
                        diferentes partes de la pantalla.</li>
                    <li><b>Sintetizadores:</b> Se crean cuatro sintetizadores, uno para cada borde de la pantalla
                        (izquierda, derecha, arriba y abajo), que producen sonidos cuando las burbujas chocan con los
                        bordes.</li>
                    <li><b>Pelotitas:</b> Se generan 20 pelotitas en posiciones aleatorias dentro del canvas.</li>
                </ul>

                <img src="./assets/funcion-setup.png" style="height: 500px;" />
                </p>

                <h3>Función draw()</h3>
                <p>Este bloque se repite muchas veces por segundo, creando un efecto de animación.</p>
                <p>Al capturar el video:</p>
                <ul>
                    <li>Se analiza cada cuadro del video en busca de movimiento.</li>
                    <li>Si se detecta movimiento, se calcula cómo las partes de la pantalla parecen moverse (flujo
                        óptico).</li>
                </ul>
                <p>Al mostrar el video:</p>
                <ul>
                    <li>Se dibuja el video capturado en el canvas para que sea visible.</li>
                </ul>

                <p>Al actualizar las pelotitas:</p>
                <ul>
                    <li>Cada pelotita se mueve y responde al flujo óptico (detecta movimiento en el video). </li>
                    <li>Las pelotitas rebotan en los bordes de la pantalla y generan sonidos cuando lo hacen.</li>
                </ul>

                <img src="./assets/funcion-draw.png" style="height: 400px;" />

                <h3>Clase Ball (Pelotitas)</h3>

                <p>Cada burbuja tiene un comportamiento único y está controlada por esta clase.</p>

                <p>Cada pelotita tiene ciertas propiedades:</p>
                <ul>
                    <li>Tiene una posición inicial (pos) y una velocidad (vel).</li>
                    <li>Su tamaño es de 30 píxeles.</li>
                    <li>Lleva un control de cuándo puede reproducir sonidos para evitar sonidos repetidos rápidamente.
                    </li>
                </ul>
                <p>Cada pelotita se mueve del siguiente modo:</p>
                <ul>
                    <li>Cada pelota ajusta su velocidad según el movimiento detectado en la cámara (flujo óptico).</li>
                    <li>Su velocidad se reduce un poco en cada cuadro para evitar que se acelere demasiado.</li>
                </ul>

                <p>Cuando una pelotita toca un borde pasa lo siguiente:</p>
                <ul>
                    <li>Rebota en él, cambiando la dirección de su movimiento.</li>
                    <li>Al chocar con un borde, genera un sonido específico dependiendo del lado (izquierda, derecha,
                        arriba o abajo).</li>
                </ul>
                <p>Finalmente:</p>
                <ul>
                    <li>La pelotita se muestra como un círculo semitransparente de color rosado.</li>
                </ul>
                <img src="./assets/clase-ball-0.png" style="height: 400px;" />
                <img src="./assets/clase-ball-1.png" style="height: 400px;" />


                <h2><a href="https://github.com/1risS/espejo-transformante/blob/main/style.css"
                        target="_blank">style.css</a></h2>
                <p>
                    En este archivo se definen los estilos de la página. Como no es lo central en el examen, no pegaré
                    las capturas del archivo
                    ya que se puede ver directamente en el repositorio haciendo click en el título.
                </p>

            </div>

            <footer>
                <p>Creado por Iris Saladino con ayuda de chatGPT</p>
            </footer>
        </div>

</body>

</html>